{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import utils\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as linalg\n",
    "import itertools\n",
    "import time\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_valid_set(savepath, df_orders, df_order_product_train):\n",
    "    # select eval set == train\n",
    "    df_order_user_curr = df_orders.loc[df_orders.eval_set == \"train\"].reset_index()\n",
    "    # only select order_id and user_id\n",
    "    df_order_user_curr = df_order_user_curr[[\"order_id\", \"user_id\"]]\n",
    "    df_order_product_valid = df_order_product_train[[\"order_id\", \"product_id\"]]\n",
    "    df_order_product_valid = df_order_product_valid.groupby(\"order_id\")[\"product_id\"].apply(list).reset_index().rename(\n",
    "        columns={\"product_id\": \"products\"})\n",
    "\n",
    "    # Merge on order id\n",
    "    df_user_product_valid = pd.merge(df_order_user_curr, df_order_product_valid, on=\"order_id\")\n",
    "    df_user_product_valid = df_user_product_valid[[\"user_id\", \"products\"]]\n",
    "\n",
    "    df_user_product_valid.to_csv(savepath, index_label=False)\n",
    "    return df_user_product_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_product_prior(savepath, df_orders, df_order_products_prior):\n",
    "    # select eval set == prior\n",
    "    df_order_user_prior = df_orders.loc[df_orders.eval_set == \"prior\"]\n",
    "    # only select order_id and user_id\n",
    "    df_order_user_prior = df_order_user_prior[[\"order_id\", \"user_id\"]]\n",
    "    # merge order_user with order_products\n",
    "    df_merged = pd.merge(df_order_user_prior, df_order_products_prior[[\"order_id\", \"product_id\"]], on=\"order_id\")\n",
    "    # select user_id and product_id only\n",
    "    df_user_product_prior = df_merged[[\"user_id\", \"product_id\"]]\n",
    "    # group the same user_id and product_id\n",
    "    df_user_product_prior = df_user_product_prior.groupby([\"user_id\", \"product_id\"]).size().reset_index().rename(\n",
    "        columns={0: \"quantity\"})\n",
    "    df_user_product_prior.to_csv(savepath, index_label=False)\n",
    "    return df_user_product_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_product_matrix(savepath, df_user_product_prior):\n",
    "    user_product_matrix = sparse.coo_matrix((df_user_product_prior[\"quantity\"],\n",
    "                                             (df_user_product_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                              df_user_product_prior[\"user_id\"].cat.codes.copy())))\n",
    "    sparse.save_npz(savepath, user_product_matrix)\n",
    "    return user_product_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spars(matrix):\n",
    "    total_size = matrix.shape[0] * matrix.shape[1]\n",
    "    actual_size = matrix.size\n",
    "    sparsity = (1 - (actual_size / total_size)) * 100\n",
    "    return sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orders shape (3421083, 7)\n"
     ]
    }
   ],
   "source": [
    "# Order datasets\n",
    "df_order_product_prior = pd.read_csv(\"order_products__prior.csv\")\n",
    "df_order_product_train = pd.read_csv(\"order_products__train.csv\")\n",
    "df_orders = pd.read_csv(\"orders.csv\")\n",
    "print('orders shape', df_orders.shape)\n",
    "\n",
    "# Products\n",
    "df_products = pd.read_csv(\"products.csv\")\n",
    "\n",
    "# Merge prior orders and products\n",
    "df_merged_order_products_prior = pd.merge(df_order_product_prior, df_products, on=\"product_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_product_valid is done\n",
      "valid shape (131209, 2)\n",
      "user_product_train is done\n",
      "train shape (13307953, 3)\n",
      "utility matrix is done\n",
      "sparsity of the utility matrix is 99.8700882953749\n"
     ]
    }
   ],
   "source": [
    "# make user_product validation set with number of reorder matrix\n",
    "valid_exist = False\n",
    "if valid_exist:\n",
    "    df_user_product_valid = pd.read_csv(\"data1/user_product_valid.csv\")\n",
    "else:\n",
    "    df_user_product_valid = make_valid_set(\"data1/user_product_valid.csv\",\n",
    "                                           df_orders, df_order_product_train)\n",
    "print('user_product_valid is done')\n",
    "print('valid shape', df_user_product_valid.shape)\n",
    "\n",
    "# make user_product train set with number of reorder matrix\n",
    "train_exist = False\n",
    "if train_exist:\n",
    "    df_user_product_train = pd.read_csv(\"data1/user_product_prior.csv\").astype('category')\n",
    "else:\n",
    "    df_user_product_train = make_user_product_prior('data1/user_product_prior.csv',\n",
    "                                                    df_orders, df_order_product_prior).astype(\"category\")\n",
    "print('user_product_train is done')\n",
    "print('train shape', df_user_product_train.shape)\n",
    "\n",
    "# make utility matrix\n",
    "matrix_exist = False\n",
    "if matrix_exist:\n",
    "    user_product_matrix = sparse.load_npz(\"data1/product_user_matrix.npz\").tocsr().astype(np.float32)\n",
    "else:\n",
    "    user_product_matrix = get_user_product_matrix(\"data1/product_user_matrix.npz\", df_user_product_train)\n",
    "print('utility matrix is done')\n",
    "print('sparsity of the utility matrix is', spars(user_product_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopNRecommendation(object):\n",
    "    def __init__(self, product_factors, user_factors, product_user_matrix):\n",
    "        self.product_factors = product_factors\n",
    "        self.user_factors = user_factors\n",
    "        self.product_user_matrix = product_user_matrix\n",
    "\n",
    "    def recommend(self, user_id, N=10):\n",
    "        \"\"\"\n",
    "        Finds top N Recommendations\n",
    "        \"\"\"\n",
    "        scores = self.user_factors[user_id] @ self.product_factors.T\n",
    "        best = np.argpartition(scores, -N)[-N:]\n",
    "        return sorted(zip(best, scores[best]), key=lambda x: -x[1])\n",
    "\n",
    "    def recommend_new(self, user_id, N=10):\n",
    "        \"\"\"\n",
    "        Finds Top N new Recommendations\n",
    "        \"\"\"\n",
    "        scores = self.user_factors[user_id] @ self.product_factors.T\n",
    "        bought_indices = self.product_user_matrix.T[user_id].nonzero()[1]\n",
    "        count = N + len(bought_indices)\n",
    "        ids = np.argpartition(scores, -count)[-count:]\n",
    "        best = sorted(zip(ids, scores[ids]), key=lambda x: -x[1])\n",
    "        return list(itertools.islice((rec for rec in best if rec[0] not in bought_indices), N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_matrix_id(df_user_product_prior):\n",
    "    u_dict = {uid: i for i, uid in enumerate(df_user_product_prior[\"user_id\"].cat.categories)}\n",
    "    p_dict = dict(enumerate(df_user_product_prior[\"product_id\"].cat.categories))\n",
    "    return u_dict, p_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actual_products(df_user_product_valid, df_products, user_id):\n",
    "    # Actual\n",
    "    row = df_user_product_valid.loc[df_user_product_valid.user_id == user_id]\n",
    "    actual = list(row[\"products\"])\n",
    "    actual = actual[0][1:-1]\n",
    "    actual = list(np.array([p.strip() for p in actual.strip().split(\",\")]).astype(np.int64))\n",
    "    act_products = []\n",
    "    for pid in actual:\n",
    "        act_products.extend(df_products.loc[df_products.product_id == pid].product_name.tolist())\n",
    "    print(\"Actual products bought by user {}\\n{}\\n\\n\".format(user_id, act_products))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_products(recommendations, df_products, p_dict, user_id):\n",
    "    # All Products Recommended\n",
    "    rec_products = []\n",
    "    for rec in recommendations:\n",
    "        print(rec)\n",
    "        rec_products.extend(df_products.loc[p_dict[rec[0]] == df_products.product_id].product_name.tolist())\n",
    "    print(\"All products recommended to user {}\\n{}\\n\\n\".format(user_id, rec_products))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_popular(k, df_order_product_prior):\n",
    "    popular_products = list(df_order_product_prior[\"product_id\"].value_counts().head(k).index)\n",
    "    return popular_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_goods(popular_products):\n",
    "    print('10 most popular products on the platform is,')\n",
    "    popular_goods = []\n",
    "    print(popular_products)\n",
    "    for rec in popular_products:\n",
    "        print(rec)\n",
    "        popular_goods.extend(df_products.loc[p_dict[rec]+1 == df_products.product_id].product_name.tolist())\n",
    "    print(popular_goods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(bought, pred):\n",
    "    if len(bought) == 0:\n",
    "        return 0\n",
    "    bought, pred = set(bought), set(pred)\n",
    "    return len(bought.intersection(pred)) / len(bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(bought, pred):\n",
    "    if len(pred) == 0:\n",
    "        return 0\n",
    "    bought, pred = set(bought), set(pred)\n",
    "    return len(bought.intersection(pred))/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(bought, pred):\n",
    "    a = precision(bought, pred)\n",
    "    b = recall(bought, pred)\n",
    "    if a+b == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * (a * b)/(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_purchase_row(row):\n",
    "    \"\"\"\n",
    "    Given a row in the validation set\n",
    "    Returns the list of new products purchased\n",
    "    \"\"\"\n",
    "    actual = row[\"products\"][1:-1]  # Products purchased currently\n",
    "    actual = set([int(p.strip()) for p in actual.strip().split(\",\")])\n",
    "    liked = set([p_dict[i] for i in user_product_matrix[u_dict[row[\"user_id\"]]].indices])  # User's purchase history\n",
    "    new_purchase = actual - liked\n",
    "    return new_purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_recommend(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when popular products are recommended\n",
    "    \"\"\"\n",
    "    actual = new_purchase_row(row)\n",
    "    return f1(actual, popular_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_recommend_new(row):\n",
    "    \"\"\"\n",
    "    Given a row in the test dataset\n",
    "    Returns the recall score when our model recommends new products\n",
    "    \"\"\"\n",
    "    actual = new_purchase_row(row)\n",
    "    recommended = svd_rec.recommend_new(u_dict[row[\"user_id\"]], N=10)\n",
    "    recommended = [p_dict[r[0]] for r in recommended]\n",
    "    return f1(actual, recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eval_df(user_product_validation, n1, n2):\n",
    "    start = time.time()\n",
    "    print(\"Making prediction on validation data ...\")\n",
    "    df_eval = user_product_validation[n1:n2].copy()\n",
    "    df_eval[\"popular_score\"] = df_eval.apply(popular_recommend, axis=1)\n",
    "    df_eval[\"svd_new_score\"] = df_eval.apply(svd_recommend_new, axis=1)\n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))\n",
    "    return df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order datasets\n",
    "df_order_products_prior = pd.read_csv(\"order_products__prior.csv\")\n",
    "df_order_products_train = pd.read_csv(\"order_products__train.csv\")\n",
    "df_orders = pd.read_csv(\"orders.csv\")\n",
    "\n",
    "# Products\n",
    "df_products = pd.read_csv(\"products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_product sets\n",
    "df_user_product_valid = pd.read_csv(\"data1/user_product_valid.csv\").astype('category')\n",
    "df_user_product_train = pd.read_csv(\"data1/user_product_prior.csv\").astype('category')\n",
    "product_user_matrix = sparse.load_npz(\"data1/product_user_matrix.npz\").tocsr().astype(np.float32)\n",
    "user_product_matrix = product_user_matrix.T.tocsr()\n",
    "u_dict, p_dict = map_matrix_id(df_user_product_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 most popular products on the platform is,\n",
      "[24852, 13176, 21137, 21903, 47209, 47766, 47626, 16797, 26209, 27845]\n",
      "24852\n",
      "13176\n",
      "21137\n",
      "21903\n",
      "47209\n",
      "47766\n",
      "47626\n",
      "16797\n",
      "26209\n",
      "27845\n",
      "['Raspberry Filmjolk Non-Fat Drinkable Yogurt', 'Country Loaf', 'Brown Fig', 'Chile Ancho', 'Premium Roast Decaf K Cup', 'Sahara Pita Pockets 100% Whole Wheat', 'Stainless Steel Sink Strainer', 'Grands! Homestyle Original', 'Quick Oats Hot Cereal', 'Diet Soda Cans']\n"
     ]
    }
   ],
   "source": [
    "# print out the 10 most popular products on the platform\n",
    "top_k = 10\n",
    "popular_products = get_k_popular(top_k, df_order_products_prior)\n",
    "print_goods(popular_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making prediction on validation data ...\n",
      "Completed in 500.04s\n",
      "Making prediction on validation data ...\n",
      "Completed in 488.16s\n",
      "Making prediction on validation data ...\n",
      "Completed in 483.12s\n",
      "Making prediction on validation data ...\n",
      "Completed in 495.62s\n",
      "svd f1 score [0.020046823925704536, 0.01996845858230009, 0.01888991423579873, 0.016593414733182616]\n",
      "Baseline f1 score [0.015445666149210972, 0.015445666149210972, 0.015445666149210972, 0.015445666149210972]\n"
     ]
    }
   ],
   "source": [
    "# tune factor number\n",
    "lambdas = [3, 5, 10, 25]\n",
    "validation_mean = []\n",
    "baseline_mean = []\n",
    "for lam in lambdas:\n",
    "    product_factors, sigma, user_factors = linalg.svds(product_user_matrix, lam)\n",
    "    user_factors = user_factors.T * sigma\n",
    "    svd_rec = TopNRecommendation(product_factors, user_factors, product_user_matrix)\n",
    "    v_mean_per_lam = []\n",
    "    b_mean_per_lam = []\n",
    "    for i in range(1):\n",
    "        k = randint(1, 2000)\n",
    "        validation_score1 = build_eval_df(df_user_product_valid, 20001, 40000)\n",
    "        validation_mean_svd_1 = np.mean(validation_score1[\"svd_new_score\"])\n",
    "        baseline_mean_1 = np.mean(validation_score1[\"popular_score\"])\n",
    "        v_mean_per_lam.append(validation_mean_svd_1)\n",
    "        b_mean_per_lam.append(baseline_mean_1)\n",
    "    v_mean = sum(v_mean_per_lam)/len(v_mean_per_lam)\n",
    "    b_mean = sum(b_mean_per_lam)/len(b_mean_per_lam)\n",
    "    validation_mean.append(v_mean)\n",
    "    baseline_mean.append(b_mean)\n",
    "print(\"svd f1 score\", validation_mean)\n",
    "print(\"Baseline f1 score\", baseline_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     Method                | Validation Set 1 | Validation Set 2 |\n",
    "|---------------------------|------------------|------------------|\n",
    "|     Baseline              | 1.54%            | 1.53%            |\n",
    "|     TF-IDF                | 15.86%           | 15.57%           |\n",
    "|     SVD with 3 factors    | 2.00%            | 2.00%            |\n",
    "|     SVD with 5 factors    | 1.99%            | 1.98%            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
